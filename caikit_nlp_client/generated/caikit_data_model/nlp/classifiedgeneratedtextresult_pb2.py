# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: caikit_data_model.nlp.classifiedgeneratedtextresult.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from caikit_nlp_client.generated.caikit_data_model.nlp import finishreason_pb2 as caikit__data__model_dot_nlp_dot_finishreason__pb2
from caikit_nlp_client.generated.caikit_data_model.nlp import textgentokenclassificationresults_pb2 as caikit__data__model_dot_nlp_dot_textgentokenclassificationresults__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n9caikit_data_model.nlp.classifiedgeneratedtextresult.proto\x12\x15\x63\x61ikit_data_model.nlp\x1a(caikit_data_model.nlp.finishreason.proto\x1a=caikit_data_model.nlp.textgentokenclassificationresults.proto\"\x9b\x02\n\x1d\x43lassifiedGeneratedTextResult\x12\x16\n\x0egenerated_text\x18\x01 \x01(\t\x12^\n\x1ctoken_classification_results\x18\x02 \x01(\x0b\x32\x38.caikit_data_model.nlp.TextGenTokenClassificationResults\x12:\n\rfinish_reason\x18\x03 \x01(\x0e\x32#.caikit_data_model.nlp.FinishReason\x12\x1d\n\x15generated_token_count\x18\x04 \x01(\x03\x12\x0c\n\x04seed\x18\x05 \x01(\x04\x12\x19\n\x11input_token_count\x18\x06 \x01(\x03\x62\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'caikit_data_model.nlp.classifiedgeneratedtextresult_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
  DESCRIPTOR._options = None
  _globals['_CLASSIFIEDGENERATEDTEXTRESULT']._serialized_start=190
  _globals['_CLASSIFIEDGENERATEDTEXTRESULT']._serialized_end=473
# @@protoc_insertion_point(module_scope)
